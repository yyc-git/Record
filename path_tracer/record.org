* TODO build basic application and render demo
render ldraw model(.ldr file)


** DONE update design

design

doc:
requirement
roadmap



** DONE summary collections



** DONE fix .dat bug

test1.dat
3626texshell.dat

should show the head!!!



update render1 service


update application


update ldr-pc



** DONE install win10


test webgpu-rtx->scene2 !


** DONE multi thread render/multi gpu core render

e.g. split sampleCount to servers, ...


*** DONE think how to parallel

multiple render workers

share the:
device
storage buffer(pixel buffer)
uniform buffer(camera buffer, render command buffer)
topLevelAS(or not?)

rt,render pipeline
gbuffer texture





*** TODO implement

test one render worker


test two render workers



test gbuffer texture



*** DONE think how to parallel2

1.我们需要服务器的显卡（RTX2060及以上的显卡）支持光线追踪
2.我们会在服务器上部署云渲染服务，提供给用户使用 （因此需要外网访问服务器，80或443端口）
3.我们需要服务器安装最新的在win10上运行的nvdia->vulkan-driver驱动（如Windows 451.98版本）（驱动下载地址：https://developer.nvidia.com/vulkan-driver -> Vulkan Beta Driver Downloads）
4.我们希望进行GPU调度，如这台服务器若有4个RTX GPU，那么就可以让我们通过代码来调度，从而实现同时让4个或更多的用户同时使用这台服务器上的不同的GPU。
通过代码（SDK）来进行下面的操作，从而让我们可以开发一个自动化调度GPU的工具：
获得有哪些GPU空闲；
设置多少个用户可以同时使用云渲染服务（互相独立不影响）；
设置某个用户使用多大的GPU资源；

5.我们希望联合多个GPU(RTX2060及以上的显卡)形成支持光线追踪的渲染农场，从而让我们可以分布式地并行渲染一个大型3D场景(使用光线追踪)

主要目的：
进行分布式渲染，得到一张3D场景的图片

思路：
其中一台服务器节点（该节点可以为一个CPU或一般的服务器）作为主节点，进行渲染任务的调配;
其他服务器节点（该节点可以为一个GPU或者GPU服务器）作为worker节点，负责渲染该图片的某个方块区域；
他们都共享场景数据；


所有服务器共享场景数据（一个buffer数据）；
主服务器需要传输渲染指令（如渲染该图片的哪个方块区域，使用哪个相机的数据等）；
GPU服务器节点负责把渲染结果（该图片的某个方块区域的数据）传输给主服务器节点；


worker节点需要win10操作系统，因为渲染引擎需要运行在GPU服务器节点上，需要win10系统+vulkan驱动




1台主机，多个GPU





我研究了下，目前渲染引擎没有找到在一台服务器上使用多个GPU的方法。

那么：
1、你这边是否可以把一台服务器的多个GPU聚合为一个GPU，让我像一个GPU那样调用？
如一台服务器有两个显存为11G的RTX 2070s，那么我可以把它当成一个GPU那样来使用（显存为22G）


回答：不能


2、你这边是否可以给我多台服务器（包含一台主服务器和多台worker服务器），每台服务器都是win10系统+只有一个RTX2070s以上的GPU，每台服务器通过http通信（最好用内网通信，速度要快！）？
这样我就可以由主服务器负责通过http通信，将渲染任务分派给各个worker服务器（只有一个GPU），然后将最终结果通过http通信传输给外界用户


回答：
可以。
主服务器和worker服务器的通信速度、主服务器与外部用户的通信速度 要看你的设计要求。



主服务器和worker服务器的通信、主服务器与外部用户的通信 都使用http通信把？

回答：
这个没问题




6.我们后期会上线云游戏服务，因此需要提供良好的网络传输和网络压缩工具等。


** DONE learn and use newest rt features
test VK_KHR_ray_tracing feature! 

https://news.developer.nvidia.com/whats-new-in-nvidia-vkray/

*** DONE learn Callable Shader
https://nvpro-samples.github.io/vk_raytracing_tutorial_KHR/vkrt_tuto_callable.md.html


*** DONE learn Ray Query
https://nvpro-samples.github.io/vk_raytracing_tutorial_KHR/vkrt_tuto_rayquery.md.htm



*** TODO webgpu node should support them!!!



** DONE learn .res

https://reasonml.org/docs/reason-compiler/latest/new-bucklescript-syntax


https://rescript-lang.org/docs/manual/latest/let-binding


*** DONE prepare dev env


////*** TODO update blog!


** DONE think engine's architecture

*** DONE recall DDD


*** DONE recall engine serials



*** DONE design engine

give architecture views

give divide domains view



externals:
WebGPU(so can work with webgpu node and webgpu in browser!!!)(now only inject with webgpu node in the entry!)
File IO




infrastructure:
interface
wonder-re-structure



rename external to dependency;

Wonder.js should be .res project!(not commit lib/, dist/ files)

remove code climate



shader files use .vert, ... instead of json;
job return Stream;
no loop, use run instead;
////jobs has no own data! get/set data to common data region in PO(in Run Domain->PO);
(e.g. get/set pass->pipelines to WebGPU->objects->pipelines, taa pass->isFirstFrame to 数据结构->通用数据->bool data map;

run->po->job data has each job's data!(e.g. gbuffer job's data)



no context postfix(e.g. rename ContextContextEntity to ContextEntity)(if duplicate, add context post fix! e.g. rename ContextEntity to ContextContextEntity);
use Root instead of Entity for Aggregate Root;
not define Root's type(type t);


////split transform to transform + link ?





build domain:
move Repo to dependency;
treat config to be dependency;

remove infrastructure layer;

convert do to po in do model;






** DONE learn spir-v unit test


** DONE learn https://www.gamasutra.com/blogs/NiklasGray/20190611/344437/Syncing_a_dataoriented_ECS_with_a_stateful_external_system.php




////** TODO write 《3D引擎实战精粹》系列

开发方法

架构

并行

优化

工程化




** DONE develop v2.0.0-alpha.1: work in Wonder.js Project

unit test

render test
(local test, not test in .travis!!!)
(change run test in nodejs to render test)

no perf test!

add .cz, test coverage, action(instead of travis), code climate, build status ...



features:
add job manager, gameObject + transform,link component, empty pass jobs(just render all pixels to blue), unit test, render test


then @wang can do:
geometry component;
gbuffer pass;


*** TODO implement

rescript
jest

//.cz


//add gameObject + transform component

//add job manager, init transform+update transform(need optimize) job:

set pipeline dp
register job

set default one



//set all dp


//refactor:
////rename gameObject->addXXX to setXXX
rename transform->addGameObject to setGameObject

//remove RepoAt




//finish init pipelines jobs

//finish run pipelines jobs






//unit test:
    in Construct:


    in CP:
        add test funcs:
        let setInitPipelineData = (data: PipelineCPVOType.pipelineData): unit => {};
        let setRestartPipelineData = (data: PipelineCPVOType.pipelineData): unit => {};
        let setRunPipelineData = (data: PipelineCPVOType.pipelineData): unit => {};




////render test



prepare for publish:

//test coverage
(> 95%)

action(instead of travis)

build status, other bars...

add 1.1 version link

publish



@wang




** TODO develop v2.0.0-alpha.2


*** DONE add all components


**** DONE logic

add pbrMaterial(no shader)

share pbrMaterial




add geometry(custom, sphere geometry)

share geometry






add cameraView, cameraProjection



add directionLight



**** DONE test



*** TODO work in Wonder-Cloud-Picture project! 

**** DONE add ray tracin pass jobs




**** DONE logic


receive the render command for distributed Ray Tracing:
////input: tile region's width,height + .wd
input: .wd(render whole picture)
////output: the tile region data(uint8Array)
output: the whole picture's data(uint8Array)



use high-performance in requestAdapter:
[Exposed=(Window, DedicatedWorker)]
interface GPU {
    Promise<GPUAdapter?> requestAdapter(optional GPURequestAdapterOptions options = {});
};

dictionary GPURequestAdapterOptions {
    GPUPowerPreference powerPreference;
};
enum GPUPowerPreference {
    "low-power",
    "high-performance"
};



add no material shaders



add init pipeline


add restart pipeline




run pipeline add passes:
update transform,
(should build transform update VO for perf!)
////gbuffer,
rt,
generate picture data,
clear






//pass compile;






***** DONE publish;





**** DONE test

***** DONE unit test

jobs:
webgpu

pass tracing

accumulation


***** DONE refactor: cloud-render should use construct's run api instead of do service!

***** DONE refactor: cloud-render should only use construct's run api instead of DPContainer

***** DONE refactor: cloud-render->CPRepoDp shouldn't dependent on CPRepo



***** DONE add Wonder-Example project

use webgpu node to implement webgpu,raytracing interface;



use file api to implement load shader file:
write interface:IFile(refer to chrome native file system:https://web.dev/native-file-system/);
implement IFile with node -> fs;




demo:
(render spheres + planes)










**** DONE publish




** TODO support textures 


*** DONE write demo

////descriptor index

////virtual texture






onion texture demo:
update texture in layers in different frames

scale to max size(2048 x 2048)



not support repeat/clamp-to-edge/mirror-repeat
(should check texCoord in [0.0, 1.0])


*** DONE learn normal map

*** DONE implement

//network dp;

//storage image uint8Array to hash map(key:image id);

//test


//pbr material add textures(diffuseMap, metalRoughnessMap, normalMap, emissionMap)
(setXXXMap(material, imageId))

//test

//geometry add a_texCoord data
(check when getTexCoords)


//test


////add init geometry job
(compute a_tangent data if has normap map)

//add these data to buffer

//test






////add init pbrMaterial texture job
(create texture view, sampler)









//add update textureArray job;

////add TextureArray do service(in webgpu->core->service)

//(only one TextureArray)


//edit init, update path tracing job;
(edit glsl)

//edit render path tracing job;

//test



*** DONE refactor

change all repo dp to return option instead of Js.Nullable.t


*** DONE run test
update example;

fix example:
main loop should only render!


add new scenes:
floor
boomBox



*** DONE add gamma

color,map should all pow(1.0/2.2)!

compare asset->texture(plane)

** DONE webgpu

** DONE publish







** DONE rethink architecture

////refactor: rename cloud-picture to path tracer


different external should only know its own data:

dependency:
config(implement):
    (refactor: po config should be external(remove setXXXCount))
    (setXxxConfigDp)
external(all inject):
    (setXxxExternalDp)
repo(only implement):
    ////map to domains(scene, statics, webgpu core, webgpu rt, ...)
    (get/setXxxRepoDp)
        ( but for pipeline domain, map to context: get/setXxxJobRepoDp )

//move job down
//change job integration test to unit test(change to upper case)

////Job shouldn't invoke repo(should through domain)

////remove some cp do service

////merge:
src
test

////remove run api


//cp api should include run api(user shouldn't invoke run api!)




////external:
prepare pipeline json data(in director?)



/*
api/ap service should map to domains(scene, statics, ...)
    (use module. e.g. module GameObject = {...} in SceneApService)
*/





** DONE refactor: rename pbr material to brdf material


** DONE add bsdf material(only Transmittance)

BSDF(specTrans, ...)

refer to  blender:
https://github.com/KhronosGroup/glTF-Blender-IO/issues/123
disney
...

*** DONE learn 1(unity)

////*** TODO learn 2(temp3)

////*** TODO learn 3(temp1)


bias for normal map?(now not bias!)



*** DONE change brdf material to bsdf material

//add transmission, ior, transmissionMap

//pass test



# add specularColor, specularMap

# pass test

# add test case(material_test)


# edit glsl
# (improve glsl by temp1.glsl)

# perf:pow5


# add comment:
# multiply NdotL for:
#     https://www.undefinedgames.org/2019/05/10/shaders-and-lighting-models/
#     c.rgb = s.Albedo * _LightColor0.rgb * (NdotL * atten);
#     NdotL multiplied with atten is where the light is applied. If either of these are zero, the whole expression becomes zero and the colour of the pixel turns black. So if the surface is no longer at an angle where it receives light, or if the light source is too far away, is when that will happen.


# etai, etat:
#      float etai = 1, etat = ior; // etai is the index of refraction of the medium the ray is in before entering the second medium 
#      in https://github.com/KhronosGroup/glTF/blob/5883dc7495754a82ef33fb635e1fc7259d472123/extensions/2.0/Khronos/KHR_materials_ior/README.md, etai = outside_ior!


pass run test(add scene3):
test default;
test only bsdf(specular brdf + refraction btdf);
test direct/indirect separatly;
test transmission + specular;
test btdf inverse effect for transmission;








////** TODO brdf material support transparent?






** DONE publish




** DONE open 1st course




*** DONE prepare summary blog article, yuque, github repo(put code here)

give cource content arrange


*** DONE contact, self introduction

add print(QQgroup:Wonder.js, QQ group 二维码)



*** DONE pass zhibo run test



*** DONE prepare content ppt

实时混合光追追踪、离线路径追踪

give cource content(main, other, selective contents) picture!

*** DONE prepare investigation to collect domains users care about;



** DONE refactor

rename ray-xxx.rgen/rchit/... to ray_xxx.xxx



** DONE finish book catalog!!!

origin book content! not change!


** TODO separate path tracer as middleware!!!???

integrate with:
open source web3d engine(e.g. threejs, babylonjs, playcanvas, cocos creator, laya, egret, ...)
open source 3d engine(e.g. godot, ...)
unity
unreal



# interface between engine and renderer:
engine should implement:
# convert engine scenegraph(e.g. for threejs -> .bin) to WDD
scene repo dp
(adapter)
(
   only get component:
   getMaterial: IBSDFMaterialData,
   getGeometry: IGeometryData,
   ...
)

use renderer in engine:
install renderer, adapter;
invoke director's api: init, update, render
(return promise instead of stream)



renderer dp:
webgpu + ray tracing(in node.js)
webgpu + compute(in browser)
network dp
time dp



renderer implement:
# assemble WDD
# render pipeline(single thread; multiple thread)
webgpu + ray tracing ->path tracing pipeline;
webgpu + compute ->path tracing pipeline;
(more:
webgpu + ray tracing ->hybrid ray tracing pipeline;
)
merge construct and run!
construct only has get function.
remove set function, po/repo implement, ...



extend renderer:
custom pipeline




wonder provide:
renderer middleware:webgpu+compute(free)
renderer middleware:webgpu+ray tracing(charge)
cloud path trace render servive(charge)


about code source:
renderer, render service not open source
renderer apadater open source

*** TODO rewrite wonder(threejs + webgpu + ray tracing(in node.js)


**** DONE first demo(only implement time job:start)

only implement init pipeline


ISceneRepo
(
    remove sceneRepo, hierachy
)

SceneRepo:
transform:{
    getTranslation(transform)
}



IJobRepo:
timeJobRepo



***** DONE rewrite wonder draft and pass compile


***** DONE unit test

test start job


test adapter?


***** DONE run test

# copy threejs node module to Wonder.js/node_modules/


write threejs adapter

run test





**** TODO render scene1,2,3

***** DONE rewrite wonder draft and pass compile

# init


# rename SceneGraphType to SceneGraphRepoType


# update


# fix: path trace scene buffer->geometry/material index


# render


***** DONE unit test


***** DONE run test


***** TODO refactor: SparseMap, HashMap->reduce should move inital value be second param like ListSt!

***** TODO refactor: rename cloud picture(CP) to webgpu ray_tracing pipeline path tracer(WRPT)



**** DONE render model!

load gltf model by threejs!


read from MeshPhysicalMaterial!

https://threejs.org/docs/#api/en/materials/MeshPhysicalMaterial






# ** TODO remove firefly



** DONE publish





# ** TODO add gltf 




# *** DONE add wdd(wonder description):
# wdd type(not has buffer,bufferView,accessor! directly use primitive data!)
# wdd parser;



# store po type


# arrayBuffer data:
# image
# position
# normal
# texCoord
# index



# indexMap:




# *** TODO assemble wdd

# # draft 

# pass compile

# commit



# # *** TODO refactor: SparseMap, HashMap->reduce should move inital value be second param like ListSt!



# *** TODO convert glb to wdd

# (no need to load glb)


# **** TODO support KHR_materials_transmission and KHR_materials_ior, KHR_materials_specular

# transmission = specTrans

# other value(e.g. flatness) use default value!!!(implement in [KHR_materials_volume](https://github.com/KhronosGroup/glTF/blob/3af4caa98cfb8bb2da4d49804a7e7947e29ad4fe/extensions/2.0/Khronos/KHR_materials_volume/README.md))






# draft 

# pass compile

# commit


# *** TODO unit test




# *** TODO run test


# **** TODO test in blender(export to gltf)

# https://github.com/KhronosGroup/glTF-Blender-IO/pull/1094



# *** TODO convert gltf zip to glb





# ////directly load gltf and build scene graph!








# **** TODO test in blender(export to gltf)

# https://github.com/KhronosGroup/glTF-Blender-IO/pull/1094

# **** TODO test specular map, transmission map


# *** TODO give demo(render gltf model)









# ** TODO remove firefly






# ** TODO publish


** TODO verify and fix specular




** TODO use RR instead of max bounce?



** TODO derive ibl, multiple lights, mis(handle specular?)




** TODO IBL


*** TODO IBL

# refer to:
# https://learnopengl.com/PBR/IBL/Diffuse-irradiance
# https://learnopengl.com/PBR/IBL/Specular-IBL

learn rayTrace.frag



learn from pbrt


importance sampling with the HDR image



refer to github code:
https://github.com/hoverinc/ray-tracing-renderer



*** TODO optimize IBL importance sample

别名法 Alias Method 优化？
https://zhuanlan.zhihu.com/p/66518450



http://www.aconty.com/pdf/fast-product-importance-abstract.pdf

[Structured Importance Sampling of Environment Maps](https://vision.cornell.edu/se3/wp-content/uploads/2014/09/54_structured.pdf)






** TODO multiple lights

*** TODO area, sphere light


*** TODO point light


*** TODO soft shadow


*** TODO many lights


** TODO fix: consider direction light's color

////** TODO fix: fix direction light's direction

now pass position and compute it in shader!

should pass direction to shader directly?





** TODO gltf with ibl, area, sphere light, point/direction light


https://github.com/KhronosGroup/glTF/issues/946

https://github.com/KhronosGroup/glTF/pull/1850



** TODO test models

from:
https://github.com/AirGuanZ/Atrc
https://casual-effects.com/g3d/data10/index.html#
https://blendswap.com/


(edit in blender! export gltf from blender?)






** TODO consider model from vray, 3ds






** TODO run test

render indoor!

compare with:
http://www.colble.com:8888/#/





** TODO publish










** TODO support render Caustics


*** TODO learn MLT

refer to:
https://www.zhihu.com/question/30016848
https://www.cnblogs.com/starfallen/p/3509234.html



learn Robust Light Transport Simulation via Metropolized Bidirectional Estimators:
https://zhuanlan.zhihu.com/p/24316493


*** TODO Manifold Exploration

https://zhuanlan.zhihu.com/p/72673165 ->Manifold Exploration

https://www.zhihu.com/question/29316802/answer/205988507


**** TODO handle Caustics
[Specular Manifold Sampling for Rendering High-Frequency Caustics and Glints](http://rgl.epfl.ch/publications/Zeltner2020Specular)

https://devtalk.blender.org/t/specular-manifold-sampling-for-cycles-caustics-and-speed/15646/14



*** TODO fix transmission shadow(BSDF)

refer to:
https://zhuanlan.zhihu.com/p/58692781
<<Ray Tracing Gems>> -> part 3?
https://stackoverflow.com/questions/13456738/shadow-rays-through-light-bending-objects
https://www.google.com/search?newwindow=1&safe=strict&sxsrf=ALeKk001aYCN6cbHsLBJnMsR2rvt6_tEKQ%3A1603448448747&ei=gK6SX5mTLcTn9QPiiKzYAQ&q=transparent+Shadow+path+trace&oq=transparent+Shadow+path+trace&gs_lcp=CgZwc3ktYWIQAzIECCMQJ1DjvgRY474EYPzJBGgAcAB4AoABpAaIAY0OkgEJMy0xLjAuMS4xmAEAoAECoAEBqgEHZ3dzLXdpesABAQ&sclient=psy-ab&ved=0ahUKEwiZ08_5vsrsAhXEc30KHWIECxsQ4dUDCA0&uact=5


this is caused with Caustics? see the Manifold Exploration or photon mapping!!!






** TODO publish






** TODO add LDR support

convert LDR to gltf, load it by three.js!

*** TODO 圆角/直角转换



*** TODO load ldr






** TODO after https://github.com/maierfelix/webgpu/pull/34 is merged and update npm, use webgpu insead of wonder-webgpu!







** TODO add blit render job(@wy)


** TODO create Rasterizer project(@wy)

add render_webgl1  pipeline



** TODO develop v2.0.0-alpha.6

*** TODO add others


**** TODO add blit pass

accu pass should after ray tracing pass


**** TODO add taa pass


**** TODO add post effect pass

tonemap
gamma


*** TODO @23 , test render gltf model!

** TODO generate picture data

*** TODO add generate pipeline to generate picture data!

init(only once);
update, render, render, ..., generate;
update, render, render, ..., generate;
...


user can specify:
picture size
sampleCount
camera data(near,far,fovy,aspect; position, target, up)
direction light data(direction, intensity)




add jobs

unit test


render test













** TODO dispose


*** TODO add dispose jobs

should reset geometry buffer;


*** TODO run test: test memory



*** TODO unit test


** TODO perf

compute time:
init,update,render pipeline's time;
the time in [update, render, generate] pipelines;


compute memory



reuse commandBuffer in render raytracing job?

use less geometry container(e.g. the same sphere should in one geometry container)









** TODO develop v2.0.0-alpha.3









** TODO move library out to be new projects

*** TODO move Array, Option, Result, ... to Wonder-Re-Structure

TODO refactor:
rename ArraySt, ListSt to Array, List
(because has namespace(WonderReStructure), so not conflict with Array, List!)





"bsc-flags": ["-open WonderReStructure"],


the api is like wonder-commonlib, but the implement can use Belt!



** TODO refactor: update wonder-bs-most,wonder-bs-sinon

stream first!




////** TODO rewrite ldr loader

use wrap type(refer to DDD)

add unit test

add test coverage, travis


** TODO ldr converter

extract from ldr-render1-service


use wrap type(refer to DDD)

add unit test

add test coverage, travis




only generate scene graph data(.wd) for render3:
input: .ldr
output: .wd


////** TODO render3 demo
load scene graph data(.wd);
use render demo to render ldr model file;

(remove denoise, taa pass, use accumulate pass to reduce noise)


*** TODO render test: render ldr model!



** TODO build engine as renderer

render test

unit test

no perf test!

add test coverage, travis, build status ...


receive the render command for distributed Ray Tracing:
input: tile region's width,height + .wd
output: the tile region data(uint8Array)






single render thread
webgpu only
ray tracing only
static scene
data: scene graph data(.wd)


fixed camera(no arcball camera)




use high-performance in requestAdapter:
[Exposed=(Window, DedicatedWorker)]
interface GPU {
    Promise<GPUAdapter?> requestAdapter(optional GPURequestAdapterOptions options = {});
};

dictionary GPURequestAdapterOptions {
    GPUPowerPreference powerPreference;
};
enum GPUPowerPreference {
    "low-power",
    "high-performance"
};







////convert .ldr to .wd;
////(extract service)

load scene graph data(.wd);
use render demo to render ldr model file;


run:
for debug


export:
snapshot data(uint8Array?)

should support stream!????




build dev env, test env;
build ci/cd tool;






optimize:
use less geometry container(e.g. the same sphere should in one geometry container)



(remove denoise, taa pass, use accumulate pass to reduce noise)










** TODO support rounded corner





////** TODO add env map



** TODO publish Wonder 2.0.0-beta

use docker for webgpu env install(e.g. vulkan driver)

** TODO add application

////set camera

////set lights

////add env map


only send ldr file
(store part file in render3 engine cloud)


*** TODO add Main Server


*** TODO add Worker Server


*** TODO add Front End Tool(very basic)


*** TODO add Scheduler

dispatch commands;
sync;
(invoke engine's init, update)



.gltf
config json


one gpu server node

one gpu server node


three.init
wonder.init

render


let picture = arrayBuffer;

picture -> base64




*** TODO add Transporter

compress

decompress



https://stackoverflow.com/questions/36091022/how-compress-typedarrays-arraybuffers-for-storage-and-transmission

https://nodejs.org/api/zlib.html#zlib_zlib
http://www.zlib.net/






** TODO deploy to cloud(distributed render)

我们希望联合多个GPU(RTX2060及以上的显卡)形成支持光线追踪的渲染农场，从而让我们可以分布式地并行渲染一个大型3D场景(使用光线追踪)

主要目的：
进行分布式渲染，得到一张3D场景的图片

思路：
其中一台服务器节点（该节点可以为一个CPU或一般的服务器）作为主节点，进行渲染任务的调配;
其他服务器节点（该节点可以为一个GPU或者GPU服务器）作为worker节点，负责渲染该图片的某个方块区域；
他们都共享场景数据；


所有服务器共享场景数据（一个buffer数据）；
主服务器需要传输渲染指令（如渲染该图片的哪个方块区域，使用哪个相机的数据等）；
GPU服务器节点负责把渲染结果（该图片的某个方块区域的数据）传输给主服务器节点；


worker节点需要win10操作系统，因为渲染引擎需要运行在GPU服务器节点上，需要win10系统+vulkan驱动



solution:
1.use one compute with multi-gpus

https://github.com/gpuweb/gpuweb/issues/995

now not support it!!! will support in pre-1.0(after MVP)


https://github.com/maierfelix/webgpu/issues/26



2.use multiple computes(each one has one gpu)


1、你这边是否可以把一台服务器的多个GPU聚合为一个GPU，让我像一个GPU那样调用？
如一台服务器有两个显存为11G的RTX 2070s，那么我可以把它当成一个GPU那样来使用（显存为22G）


回答：不能


2、你这边是否可以给我多台服务器（包含一台主服务器和多台worker服务器），每台服务器都是win10系统+只有一个RTX2070s以上的GPU，每台服务器通过http通信（最好用内网通信，速度要快！）？
这样我就可以由主服务器负责通过http通信，将渲染任务分派给各个worker服务器（只有一个GPU），然后将最终结果通过http通信传输给外界用户


回答：
可以。
主服务器和worker服务器的通信速度、主服务器与外部用户的通信速度 要看你的设计要求。



主服务器和worker服务器的通信、主服务器与外部用户的通信 都使用http通信把？

回答：
这个没问题






最终方案：
租用一台gpu服务器（一个服务器1个RTX 2070s显卡）作为worker服务器（gpu服务器店铺：https://shop392735765.taobao.com/?spm=2013.1.1000126.2.66cf1e6bdi61c0 );
然后租用一台云服务器作为主服务器，两者通过http传输二进制文件;
主服务器与Front End Tool通过http通信；

一台worker node渲染一整张图片！


可考虑把我这台电脑作为worker服务器！（@王影）





** TODO add weixin login


** TODO add weixin payment


** TODO add website, document


** TODO publish

publish Wonder.js v2.0.0